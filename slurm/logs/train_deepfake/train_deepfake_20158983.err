 > Training Environment:
 | > Backend: Torch
 | > Mixed precision: False
 | > Precision: float32
 | > Current device: 0
 | > Num. of GPUs: 1
 | > Num. of CPUs: 48
 | > Num. of Torch Threads: 1
 | > Torch seed: 1
 | > Torch CUDNN: True
 | > Torch CUDNN deterministic: False
 | > Torch CUDNN benchmark: False
 | > Torch TF32 MatMul: False
 > Start Tensorboard: tensorboard --logdir=/home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b

 > Model has 518442047 parameters

[4m[1m > EPOCH: 0/1000[0m
 --> /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b

[1m > EVALUATION [0m

/home/henryj/deepfake/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py:277: UserWarning: "kaiser_window" resampling method name is being deprecated and replaced by "sinc_interp_kaiser" in the next release. The default behavior remains unchanged.
  dvae_wav = torchaudio.functional.resample(
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torchaudio/functional/functional.py:1466: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  resampled = torch.nn.functional.conv1d(waveform[:, None], kernel, stride=orig_freq)
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,

  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time: 0.9479527473449707 [0m(+0)
     | > avg_loss_text_ce: 0.023295346647500992 [0m(+0)
     | > avg_loss_mel_ce: 2.736766815185547 [0m(+0)
     | > avg_loss: 2.7600622177124023 [0m(+0)


[4m[1m > EPOCH: 1/1000[0m
 --> /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

[1m > TRAINING (2024-05-07 09:39:29) [0m

[1m   --> TIME: 2024-05-07 09:39:37 -- STEP: 0/52 -- GLOBAL_STEP: 0[0m
     | > loss_text_ce: 0.020248323678970337  (0.020248323678970337)
     | > loss_mel_ce: 2.5599613189697266  (2.5599613189697266)
     | > loss: 0.030716782435774803  (0.030716782435774803)
     | > current_lr: 5e-06 
     | > step_time: 1.3092  (1.3092041015625)
     | > loader_time: 6.166  (6.165950775146484)


[1m   --> TIME: 2024-05-07 09:39:56 -- STEP: 50/52 -- GLOBAL_STEP: 50[0m
     | > loss_text_ce: 0.02267536334693432  (0.021856528148055075)
     | > loss_mel_ce: 2.766902208328247  (2.8192821216583246)
     | > loss: 0.03320925682783127  (0.03382307987660171)
     | > current_lr: 5e-06 
     | > step_time: 0.2527  (0.2591445159912109)
     | > loader_time: 0.0052  (0.0319791316986084)


[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 0.02706456184387207 [0m(-0.9208881855010986)
     | > avg_loss_text_ce:[92m 0.02319764345884323 [0m(-9.770318865776062e-05)
     | > avg_loss_mel_ce:[92m 2.6377623081207275 [0m(-0.09900450706481934)
     | > avg_loss:[92m 2.6609599590301514 [0m(-0.09910225868225098)

 > BEST MODEL : /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b/best_model_52.pth

[4m[1m > EPOCH: 2/1000[0m
 --> /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b

[1m > TRAINING (2024-05-07 09:40:22) [0m

[1m   --> TIME: 2024-05-07 09:40:45 -- STEP: 48/52 -- GLOBAL_STEP: 100[0m
     | > loss_text_ce: 0.024845417588949203  (0.021496274314510327)
     | > loss_mel_ce: 2.836362361907959  (2.739356900254885)
     | > loss: 0.03406199812889099  (0.03286730020772666)
     | > current_lr: 5e-06 
     | > step_time: 0.2069  (0.3001106282075246)
     | > loader_time: 0.0053  (0.010578994949658712)


[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 0.13747739791870117 [0m(+0.1104128360748291)
     | > avg_loss_text_ce:[92m 0.023126300424337387 [0m(-7.134303450584412e-05)
     | > avg_loss_mel_ce:[92m 2.5522499084472656 [0m(-0.08551239967346191)
     | > avg_loss:[92m 2.575376272201538 [0m(-0.08558368682861328)

 > BEST MODEL : /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b/best_model_104.pth
 ! Run is kept in /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+39AM-6c5de6b
Traceback (most recent call last):
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/serialization.py", line 628, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/serialization.py", line 862, in _save
    zip_file.write_record(name, storage, num_bytes)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/fsspec/implementations/local.py", line 389, in write
    return self.f.write(*args, **kwargs)
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/trainer.py", line 1833, in fit
    self._fit()
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/trainer.py", line 1796, in _fit
    self.save_best_model()
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/utils/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/trainer.py", line 1916, in save_best_model
    self.best_loss = save_best_model(
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/io.py", line 199, in save_best_model
    save_model(
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/io.py", line 132, in save_model
    save_func(state, output_path)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/utils/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/logging/base_dash_logger.py", line 62, in save_model
    save_fsspec(state, path)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/io.py", line 98, in save_fsspec
    torch.save(state, f, **kwargs)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/serialization.py", line 627, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/serialization.py", line 491, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:595] . unexpected pos 770316224 vs 770316112
