 > Training Environment:
 | > Backend: Torch
 | > Mixed precision: False
 | > Precision: float32
 | > Current device: 0
 | > Num. of GPUs: 1
 | > Num. of CPUs: 48
 | > Num. of Torch Threads: 1
 | > Torch seed: 1
 | > Torch CUDNN: True
 | > Torch CUDNN deterministic: False
 | > Torch CUDNN benchmark: False
 | > Torch TF32 MatMul: False
 > Start Tensorboard: tensorboard --logdir=/home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+29AM-6c5de6b

 > Model has 518442047 parameters

[4m[1m > EPOCH: 0/1000[0m
 --> /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+29AM-6c5de6b

[1m > EVALUATION [0m

/home/henryj/deepfake/venv/lib/python3.10/site-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py:277: UserWarning: "kaiser_window" resampling method name is being deprecated and replaced by "sinc_interp_kaiser" in the next release. The default behavior remains unchanged.
  dvae_wav = torchaudio.functional.resample(
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torchaudio/functional/functional.py:1466: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  resampled = torch.nn.functional.conv1d(waveform[:, None], kernel, stride=orig_freq)
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,

  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time: 9.417984008789062 [0m(+0)
     | > avg_loss_text_ce: 0.023295346647500992 [0m(+0)
     | > avg_loss_mel_ce: 2.736766815185547 [0m(+0)
     | > avg_loss: 2.7600622177124023 [0m(+0)


[4m[1m > EPOCH: 1/1000[0m
 --> /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+29AM-6c5de6b
/home/henryj/deepfake/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

[1m > TRAINING (2024-05-07 09:30:01) [0m

[1m   --> TIME: 2024-05-07 09:30:10 -- STEP: 0/52 -- GLOBAL_STEP: 0[0m
     | > loss_text_ce: 0.020248323678970337  (0.020248323678970337)
     | > loss_mel_ce: 2.5599613189697266  (2.5599613189697266)
     | > loss: 0.030716782435774803  (0.030716782435774803)
     | > current_lr: 5e-06 
     | > step_time: 2.1862  (2.1862497329711914)
     | > loader_time: 6.7371  (6.737089395523071)


[1m   --> TIME: 2024-05-07 09:30:28 -- STEP: 50/52 -- GLOBAL_STEP: 50[0m
     | > loss_text_ce: 0.02267536334693432  (0.021856528148055072)
     | > loss_mel_ce: 2.766902208328247  (2.819282112121582)
     | > loss: 0.03320925682783127  (0.03382307980209588)
     | > current_lr: 5e-06 
     | > step_time: 0.2527  (0.2506717681884766)
     | > loader_time: 0.0053  (0.018550596237182616)


[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 0.027762889862060547 [0m(-9.390221118927002)
     | > avg_loss_text_ce:[92m 0.02319764345884323 [0m(-9.770318865776062e-05)
     | > avg_loss_mel_ce:[92m 2.6377623081207275 [0m(-0.09900450706481934)
     | > avg_loss:[92m 2.6609599590301514 [0m(-0.09910225868225098)

--- Logging error ---
Exception in thread Thread-1:
Exception in threading.excepthook:
Traceback (most recent call last):
  File "/home/henryj/deepfake/venv/lib/python3.10/threading.py", line 1326, in invoke_excepthook
 ! Run is removed from /home/henryj/deepfake/training_data/scripts/run/training/GPT_XTTS_v2.0_LJSpeech_FT-May-07-2024_09+29AM-6c5de6b
    hook(args)
OSError: [Errno 122] Disk quota exceeded
Traceback (most recent call last):
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/trainer.py", line 1833, in fit
    self._fit()
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/trainer.py", line 1791, in _fit
    self.c_logger.print_epoch_end(
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/utils/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/logging/console_logger.py", line 115, in print_epoch_end
    self.log_with_flush(log_text)
  File "/home/henryj/deepfake/venv/lib/python3.10/site-packages/trainer/logging/console_logger.py", line 35, in log_with_flush
    handler.flush()
  File "/home/henryj/deepfake/venv/lib/python3.10/logging/__init__.py", line 1084, in flush
    self.stream.flush()
OSError: [Errno 122] Disk quota exceeded
